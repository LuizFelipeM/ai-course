{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EB1tzz4Wku9-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Input\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, _), (X_test, _) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xyRDeWMmfgG",
        "outputId": "3c185f5a-a628-4994-b42d-4de25b733ce8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype(\"float32\")/255.0\n",
        "X_test = X_test.astype(\"float32\")/255.0"
      ],
      "metadata": {
        "id": "U-Bchq1Zmk6p"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
        "X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))"
      ],
      "metadata": {
        "id": "3PJAwBEomxAe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_noisy = X_test + 0.5 * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape)\n",
        "X_test_noisy = np.clip(X_test_noisy, 0.0, 1.0)"
      ],
      "metadata": {
        "id": "bjH18J9Nm9NI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(784,))\n",
        "encoder = Dense(32, activation=\"relu\")(inputs)\n",
        "decoder = Dense(784, activation=\"sigmoid\")(encoder)\n",
        "autoencoder = Model(inputs, decoder)\n",
        "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
        "autoencoder.fit(X_train, X_train, epochs=100, batch_size=256, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1EfHqEwnLXh",
        "outputId": "b2e7dc7a-2a15-4950-ef98-947252f4cb21"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "235/235 [==============================] - 7s 5ms/step - loss: 0.2756\n",
            "Epoch 2/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1693\n",
            "Epoch 3/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1434\n",
            "Epoch 4/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1277\n",
            "Epoch 5/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1175\n",
            "Epoch 6/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1105\n",
            "Epoch 7/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1057\n",
            "Epoch 8/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1022\n",
            "Epoch 9/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0995\n",
            "Epoch 10/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0976\n",
            "Epoch 11/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0963\n",
            "Epoch 12/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0954\n",
            "Epoch 13/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0949\n",
            "Epoch 14/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0945\n",
            "Epoch 15/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0942\n",
            "Epoch 16/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0940\n",
            "Epoch 17/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0938\n",
            "Epoch 18/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0936\n",
            "Epoch 19/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0935\n",
            "Epoch 20/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0934\n",
            "Epoch 21/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0933\n",
            "Epoch 22/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0932\n",
            "Epoch 23/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0932\n",
            "Epoch 24/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0931\n",
            "Epoch 25/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0931\n",
            "Epoch 26/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0930\n",
            "Epoch 27/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0930\n",
            "Epoch 28/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0929\n",
            "Epoch 29/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0929\n",
            "Epoch 30/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0929\n",
            "Epoch 31/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0929\n",
            "Epoch 32/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0928\n",
            "Epoch 33/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0928\n",
            "Epoch 34/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0928\n",
            "Epoch 35/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0928\n",
            "Epoch 36/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0927\n",
            "Epoch 37/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0927\n",
            "Epoch 38/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0927\n",
            "Epoch 39/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0927\n",
            "Epoch 40/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0927\n",
            "Epoch 41/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0927\n",
            "Epoch 42/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0926\n",
            "Epoch 43/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0926\n",
            "Epoch 44/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0926\n",
            "Epoch 45/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0926\n",
            "Epoch 46/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0926\n",
            "Epoch 47/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0926\n",
            "Epoch 48/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0926\n",
            "Epoch 49/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0926\n",
            "Epoch 50/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0926\n",
            "Epoch 51/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0926\n",
            "Epoch 52/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0926\n",
            "Epoch 53/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0926\n",
            "Epoch 54/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0925\n",
            "Epoch 55/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0925\n",
            "Epoch 56/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0925\n",
            "Epoch 57/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0925\n",
            "Epoch 58/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0925\n",
            "Epoch 59/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0925\n",
            "Epoch 60/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0925\n",
            "Epoch 61/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0925\n",
            "Epoch 62/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0925\n",
            "Epoch 63/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0925\n",
            "Epoch 64/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0925\n",
            "Epoch 65/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0925\n",
            "Epoch 66/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0925\n",
            "Epoch 67/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0925\n",
            "Epoch 68/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0925\n",
            "Epoch 69/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0924\n",
            "Epoch 70/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0924\n",
            "Epoch 71/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0924\n",
            "Epoch 72/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0924\n",
            "Epoch 73/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0924\n",
            "Epoch 74/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0924\n",
            "Epoch 75/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0924\n",
            "Epoch 76/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0924\n",
            "Epoch 77/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0924\n",
            "Epoch 78/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0924\n",
            "Epoch 79/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0924\n",
            "Epoch 80/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0924\n",
            "Epoch 81/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0924\n",
            "Epoch 82/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0924\n",
            "Epoch 83/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0924\n",
            "Epoch 84/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0924\n",
            "Epoch 85/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0924\n",
            "Epoch 86/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0924\n",
            "Epoch 87/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0924\n",
            "Epoch 88/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0924\n",
            "Epoch 89/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0924\n",
            "Epoch 90/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0923\n",
            "Epoch 91/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0923\n",
            "Epoch 92/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0923\n",
            "Epoch 93/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0923\n",
            "Epoch 94/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0923\n",
            "Epoch 95/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0923\n",
            "Epoch 96/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0923\n",
            "Epoch 97/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0923\n",
            "Epoch 98/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0923\n",
            "Epoch 99/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0923\n",
            "Epoch 100/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0923\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cbee0d15f90>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_normal_decoded = autoencoder.predict(X_test)\n",
        "test_anomalies_decoded = autoencoder.predict(X_test_noisy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYamAg8gnu2l",
        "outputId": "a21f8d75-49f6-4152-9bb7-42dcc967c330"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_normal = mean_squared_error(X_test, test_normal_decoded)\n",
        "mse_anomalies = mean_squared_error(X_test_noisy, test_anomalies_decoded)\n",
        "\n",
        "print(f\"MSE Normal = {mse_normal} \\nMSE Anomalies = {mse_anomalies}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d_rM9CxxFn4",
        "outputId": "b1a95a6f-1267-463c-a956-37288945866f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Normal = 0.009549878537654877 \n",
            "MSE Anomalies = 0.1690354284270883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"MSE Delta = {mse_anomalies - mse_normal}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-I_ObvjxY8N",
        "outputId": "64749dc2-b474-46c7-a4cb-5873919198af"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Delta = 0.15948554988943342\n"
          ]
        }
      ]
    }
  ]
}